{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a79c4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service import catalog as c\n",
    "from databricks.sdk.service.workspace import (\n",
    "    ScopeBackendType, AzureKeyVaultSecretScopeMetadata\n",
    ")\n",
    "from databricks.sdk.service.settings import TokenAccessControlRequest, TokenPermissionLevel\n",
    "\n",
    "import yaml\n",
    "\n",
    "with open(\"../config.yml\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "w = WorkspaceClient(host=cfg[\"workspace_url\"], auth_type = 'azure-cli')\n",
    "\n",
    "# storage x access connector\n",
    "access_connector_id = f\"/subscriptions/{cfg[\"subscription_id\"]}/resourceGroups/rg-medisure-dev/providers/Microsoft.Databricks/accessConnectors/dac-medisure-dev\"\n",
    "sa_name = \"samedisuredev\"\n",
    "\n",
    "# secrets x keyvault\n",
    "SCOPE_NAME = \"medisure-dev\"\n",
    "KV_RESOURCE_ID = f\"/subscriptions/{cfg[\"subscription_id\"]}/resourceGroups/rg-medisure-dev/providers/Microsoft.KeyVault/vaults/kv-medisure-dev\"\n",
    "KV_DNS_NAME    = \"https://kv-medisure-dev.vault.azure.net/\"\n",
    "\n",
    "# databricks storage credentials\n",
    "cred_name = \"cred_medisure_dev\"\n",
    "\n",
    "# external location\n",
    "ext_name   = \"ext_medisure_landing_dev\"\n",
    "ext_delta_files_name = \"ext_medisure_delta_files_dev\"\n",
    "\n",
    "#catalog\n",
    "catalog   = \"medisure_dev\"\n",
    "\n",
    "# ABFSS URLs\n",
    "abfss_url =  f\"abfss://landing@{sa_name}.dfs.core.windows.net/\"\n",
    "managed_delta_files_url =  f\"abfss://managed-delta-files@{sa_name}.dfs.core.windows.net/\"\n",
    "\n",
    "# service principal\n",
    "service_principal_name = \"medisure dev - workflows\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b468ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Storage Credential (via Access Connector) ---\n",
    "try:\n",
    "    w.storage_credentials.get(name=cred_name)\n",
    "    print(f\"Storage credential '{cred_name}' already exists\")\n",
    "except Exception:\n",
    "    w.storage_credentials.create(\n",
    "        name=cred_name,\n",
    "        azure_managed_identity=c.AzureManagedIdentity(\n",
    "            access_connector_id=access_connector_id\n",
    "        ),\n",
    "        comment=\"ADLS Gen2 via Azure Databricks Access Connector (dev)\"\n",
    "    )\n",
    "    print(f\"Created storage credential '{cred_name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4480f8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- External Locations  ---\n",
    "\n",
    "try:\n",
    "    w.external_locations.get(name=ext_name)\n",
    "    print(f\"External location '{ext_name}' already exists\")\n",
    "except Exception:\n",
    "    w.external_locations.create(\n",
    "        name=ext_name,\n",
    "        url=abfss_url,\n",
    "        credential_name=cred_name,\n",
    "        comment=f\"{ext_name} location\"\n",
    "    )\n",
    "    print(f\"Created external location '{ext_name}' -> {abfss_url}\")\n",
    "\n",
    "try:\n",
    "    w.external_locations.get(name=ext_delta_files_name)\n",
    "    print(f\"External location '{ext_delta_files_name}' already exists\")\n",
    "except Exception:\n",
    "    w.external_locations.create(\n",
    "        name=ext_delta_files_name,\n",
    "        url=managed_delta_files_url,\n",
    "        credential_name=cred_name,\n",
    "        comment=f\"{ext_delta_files_name} location\"\n",
    "    )\n",
    "    print(f\"Created external location '{ext_delta_files_name}' -> {managed_delta_files_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb234b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Catalog (with managed location) ---\n",
    "managed_root = managed_delta_files_url\n",
    "\n",
    "try:\n",
    "    w.catalogs.get(name=catalog)\n",
    "    print(f\"Catalog '{catalog}' already exists\")\n",
    "except Exception:\n",
    "    w.catalogs.create(\n",
    "        name=catalog,\n",
    "        comment=\"MediSure dev catalog\",\n",
    "        storage_root=managed_root,     # makes catalog 'managed' at this path\n",
    "    )\n",
    "    print(f\"Created catalog '{catalog}' with storage_root {managed_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcfe445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Schemas: bronze/silver/gold --- to be created as part of application\n",
    "# for schema in [\"bronze\", \"silver\", \"gold\"]:\n",
    "#     full = f\"{catalog}.{schema}\"\n",
    "#     try:\n",
    "#         w.schemas.get(full_name=full)\n",
    "#         print(f\"Schema '{full}' already exists\")\n",
    "#     except Exception:\n",
    "#         w.schemas.create(name=schema, catalog_name=catalog, comment=f\"{schema} layer\")\n",
    "#         print(f\"Created schema '{full}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8797d45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Secrets: azure key vault ---\n",
    "existing = [s.name for s in w.secrets.list_scopes()]\n",
    "if SCOPE_NAME in existing:\n",
    "    print(f\"Scope '{SCOPE_NAME}' already exists.\")\n",
    "else:\n",
    "    w.secrets.create_scope(\n",
    "        scope=SCOPE_NAME,\n",
    "        scope_backend_type=ScopeBackendType.AZURE_KEYVAULT,\n",
    "        backend_azure_keyvault=AzureKeyVaultSecretScopeMetadata(\n",
    "            resource_id=KV_RESOURCE_ID,\n",
    "            dns_name=KV_DNS_NAME\n",
    "        )\n",
    "    )\n",
    "    print(f\"Created AKV-backed scope '{SCOPE_NAME}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0ef0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Service Principal for Workflows ---\n",
    "sp = w.service_principals.create(display_name=f\"{service_principal_name}\")\n",
    "print(\"created service principal:\", sp.application_id, sp.display_name)\n",
    "\n",
    "# grant access to catalog; service principals will create schema and all objects so by default it becomes owner\n",
    "\n",
    "w.grants.update(\n",
    "    securable_type=\"CATALOG\",\n",
    "    full_name=catalog,\n",
    "    changes=[\n",
    "        c.PermissionsChange(\n",
    "            principal=sp.application_id,\n",
    "            add=[c.Privilege.USE_CATALOG, c.Privilege.CREATE_SCHEMA]\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d1b58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Service Principal for Deployment ---\n",
    "sp = w.service_principals.create(display_name=\"github deploy - dev\")\n",
    "print(\"created service principal:\", sp.application_id, sp.display_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae779569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create token for self to open up token permission settings; without this we cannot grant access to tokens, because no tokens exist yet\n",
    "w.tokens.create(comment=\"initial token\",lifetime_seconds=60)\n",
    "\n",
    "# allow access to tokens for service principal\n",
    "access_control_list = [\n",
    "    TokenAccessControlRequest(\n",
    "        service_principal_name=sp.application_id,\n",
    "        permission_level=TokenPermissionLevel.CAN_USE,  # Use the enum value\n",
    "    )\n",
    "]\n",
    "\n",
    "token_permissions = w.token_management.update_permissions(\n",
    "    access_control_list=access_control_list\n",
    ")\n",
    "token_permissions.as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e4faae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# does not work on Azure, it is possibly blocked\n",
    "# # Create a PAT on behalf of the SP\n",
    "# obo = w.token_management.create_obo_token(\n",
    "#     application_id=sp.application_id,          # the SPâ€™s application (client) ID\n",
    "#     comment=\"github-deploy dev\",\n",
    "#     lifetime_seconds=60 * 60 * 24 * 30         # 30 days; adjust to your policy\n",
    "# )\n",
    "\n",
    "# print(\"TOKEN_ID:\", obo.token_info.token_id)\n",
    "# print(\"TOKEN_VALUE (copy now):\", obo.token_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec841a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create client secret as service principal\n",
    "create_secrets_response = w.service_principal_secrets_proxy.create(service_principal_id=sp.id)\n",
    "\n",
    "# login as service principal\n",
    "w_as_sp = WorkspaceClient(host=cfg[\"workspace_url\"],\n",
    "                client_id = sp.application_id,\n",
    "                client_secret = create_secrets_response.secret,\n",
    "                auth_type='oauth-m2m'\n",
    "                )\n",
    "\n",
    "# create token as service principal\n",
    "create_token_response = w_as_sp.tokens.create(\n",
    "    comment = sp.display_name,\n",
    "    lifetime_seconds=-1)\n",
    "\n",
    "delete_secrets_response = w.service_principal_secrets_proxy.delete(\n",
    "    service_principal_id=sp.id, \n",
    "    secret_id=create_secrets_response.id)\n",
    "\n",
    "print(create_secrets_response)\n",
    "print(create_token_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azure-databricks-training-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
